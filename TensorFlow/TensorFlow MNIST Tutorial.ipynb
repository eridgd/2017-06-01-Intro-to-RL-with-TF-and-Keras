{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Demo: MNIST for ML Beginners\n",
    "Before start using this, please select `Cell` - `All Output` - `Clear` to clear the old results. \n",
    "\n",
    "This is taken from the [TensorFlow Tutorial](https://www.tensorflow.org/get_started/mnist/beginners), refer to that for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading MNIST training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Images\n",
    "![mnist.train.xs](https://www.tensorflow.org/versions/master/images/mnist-train-xs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST training images matrix shape\n",
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.23137257,  0.63921571,  0.99607849,  0.99607849,  0.99607849,\n",
       "         0.76078439,  0.43921572,  0.07058824,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.01568628,  0.51764709,\n",
       "         0.93725497,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99607849,  0.99215692,  0.627451  ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.53725493,  0.99215692,\n",
       "         0.99607849,  0.99215692,  0.99215692,  0.99215692,  0.75294125,\n",
       "         0.99607849,  0.99215692,  0.89803928,  0.0509804 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.01568628,  0.53725493,  0.98431379,  0.99215692,\n",
       "         0.95686281,  0.50980395,  0.19215688,  0.07450981,  0.01960784,\n",
       "         0.63921571,  0.99215692,  0.82352948,  0.03529412,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.37254903,  0.99215692,  0.99215692,  0.84313732,\n",
       "         0.17647059,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.61176473,  0.99215692,  0.68235296,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.84313732,  0.99607849,  0.81176478,  0.09019608,\n",
       "         0.        ,  0.        ,  0.        ,  0.03921569,  0.38039219,\n",
       "         0.85098046,  0.91764712,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.83921576,  0.99215692,  0.27843139,  0.        ,\n",
       "         0.        ,  0.00784314,  0.19607845,  0.83529419,  0.99215692,\n",
       "         0.99607849,  0.70588237,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.83921576,  0.99215692,  0.19215688,  0.        ,\n",
       "         0.        ,  0.19607845,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.71764708,  0.04705883,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.78039223,  0.99215692,  0.95294124,  0.76862752,\n",
       "         0.62352943,  0.95294124,  0.99215692,  0.96862751,  0.5411765 ,\n",
       "         0.03137255,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.16470589,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.99607849,  0.99215692,  0.99215692,  0.39607847,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.23137257,  0.58431375,  0.99607849,  0.99607849,  0.99607849,\n",
       "         1.        ,  0.99607849,  0.68627453,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.13333334,  0.75294125,\n",
       "         0.99607849,  0.99215692,  0.99215692,  0.99215692,  0.7843138 ,\n",
       "         0.53333336,  0.89019614,  0.9450981 ,  0.27058825,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.33333334,  0.96862751,  0.99215692,\n",
       "         0.99607849,  0.99215692,  0.77647066,  0.48235297,  0.07058824,\n",
       "         0.        ,  0.19607845,  0.99215692,  0.83529419,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.27843139,  0.96862751,  0.99215692,  0.92941183,\n",
       "         0.75294125,  0.27843139,  0.02352941,  0.        ,  0.        ,\n",
       "         0.        ,  0.00784314,  0.50196081,  0.98039222,  0.21176472,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.46274513,  0.99215692,  0.8705883 ,  0.14117648,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.03137255,  0.71764708,  0.99215692,  0.227451  ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.46274513,  0.99607849,  0.54509807,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.05490196,  0.72941178,  0.99607849,  0.99607849,  0.227451  ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.27843139,  0.96862751,  0.96862751,  0.54509807,\n",
       "         0.0627451 ,  0.        ,  0.        ,  0.07450981,  0.227451  ,\n",
       "         0.87843144,  0.99215692,  0.99215692,  0.83137262,  0.03529412,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.42352945,  0.99215692,  0.99215692,\n",
       "         0.92549026,  0.68627453,  0.68627453,  0.96862751,  0.99215692,\n",
       "         0.99607849,  0.99215692,  0.77647066,  0.16862746,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.26274511,  0.83529419,  0.89803928,\n",
       "         0.99607849,  0.99215692,  0.99215692,  0.99215692,  0.99215692,\n",
       "         0.83921576,  0.48627454,  0.02352941,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.09019608,\n",
       "         0.60784316,  0.60784316,  0.87450987,  0.7843138 ,  0.46274513,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST training images matrix data\n",
    "sample_img = mnist.train.images[5].reshape(28, 28)\n",
    "sample_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPxAU4QeCIvxAUIQfCIrwA0ERfiCo/wfTzIQu0aA6UAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f757518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the image\n",
    "plt.imshow(sample_img).set_cmap('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Labels\n",
    "![mnist.train.ys](https://www.tensorflow.org/versions/master/images/mnist-train-ys.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check MNIST labels shape\n",
    "mnist.train.labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show MNIST label data\n",
    "sample_label = mnist.train.labels[5]\n",
    "sample_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## in a graph:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-scalargraph.png)\n",
    "\n",
    "## in a vector equation:\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-regression-vectorequation.png)\n",
    "\n",
    "## so that we'll have the weights like this:\n",
    "blue: positive weights, red: negative weights\n",
    "![](https://www.tensorflow.org/versions/master/images/softmax-weights.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax_1:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a neural network (softmax logistic regression)\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='x_img') # placeholder vals are provided in a feed_dict when eval/running\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b) # the equation\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Train Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Operation 'GradientDescent_1' type=NoOp>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the train step to minimize the cross entropy with SGD\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])    # placeholder for the correct label\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))   # cross ent is the log of the predicted prob of the correct label\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cross_entropy)\n",
    "train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Gradient Decent to find the optimal weights\n",
    "![](http://blog.datumbox.com/wp-content/uploads/2013/10/gradient-descent.png)\n",
    "From: [Machine Learning Blog & Software Development News](http://blog.datumbox.com/tuning-the-learning-rate-in-gradient-descent/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do 1000 rounds of mini-batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables and session\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "\n",
    "# train the model mini batch with 100 elements, for 1K times\n",
    "for i in range(1000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})  # feed_dict provides values to placeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict for a few samples from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred:   [7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n",
      "Actual: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xs = mnist.test.images[:30]\n",
    "ys = mnist.test.labels[:30]\n",
    "print(\"Pred:  \", np.argmax(y.eval(feed_dict={x: xs}), axis=1))# Prediction is the col # with highest prob\n",
    "print(\"Actual:\", np.argmax(ys, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy on entire test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9165\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy of the model\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
